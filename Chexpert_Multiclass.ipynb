{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CS 7643: Deep Learning Group Project\n",
    "# CheXpert Reproducibility - Multiclass Uncertainty Approach\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.multiclass import unique_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_multiclass_loss(criterion, output, target):\n",
    "    # set up loss function\n",
    "    loss, length = 0, target.size()[1] \n",
    "    for i in range(length):\n",
    "        loss += criterion(output[:,i,:], target[:,i])\n",
    "\n",
    "    return loss/length\n",
    "\n",
    "# helper function to store average/current value\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "# compute accuracy by batch \n",
    "def compute_batch_accuracy(output, target):\n",
    "    with torch.no_grad():\n",
    "        batch_size = target.size(0)\n",
    "        output_label = torch.sigmoid(output)\n",
    "        pred = (torch.sign(output_label - 0.5)+1)/2\n",
    "        correct = pred.eq(target).sum()\n",
    "        return correct * 100.0 / batch_size\n",
    "\n",
    "\n",
    "def train(model, device, data_loader, criterion, optimizer, epoch, print_freq=10):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(data_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if isinstance(input, tuple):\n",
    "            input = tuple([e.to(device) if type(e) == torch.Tensor else e for e in input])\n",
    "        else:\n",
    "            input = input.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input) \n",
    "        # get mean of CrossEntropyLoss() over 14 labels\n",
    "        loss = u_multiclass_loss(criterion,output, target)\n",
    "        assert not np.isnan(loss.item()), 'Model diverged with loss = NaN'\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        losses.update(loss.item(), target.size(0))\n",
    "        # print statement with loss updates \n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(\n",
    "                epoch, i, len(data_loader), batch_time=batch_time,\n",
    "                data_time=data_time, loss=losses))\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def evaluate(model, device, data_loader, criterion, print_freq=10):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(data_loader):\n",
    "\n",
    "            if isinstance(input, tuple):\n",
    "                input = tuple([e.to(device) if type(e) == torch.Tensor else e for e in input])\n",
    "            else:\n",
    "                input = input.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(input) \n",
    "            # mean of CrossEntropyLoss() over 14 labels\n",
    "            loss = u_multiclass_loss(criterion, output, target) \n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            losses.update(loss.item(), target.size(0))\n",
    "\n",
    "            y_true = target.detach().to('cpu').numpy().tolist()\n",
    "            y_pred = output.detach().to('cpu').max(-1)[1].numpy().tolist()\n",
    "            results.extend(list(zip(y_true, y_pred)))\n",
    "\n",
    "            if i % print_freq == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(\n",
    "                    i, len(data_loader), batch_time=batch_time, loss=losses))\n",
    "\n",
    "    return losses.avg, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(train_losses, valid_losses):\n",
    "    PATH_OUTPUT = '../output/'\n",
    "    image_path = os.path.join(PATH_OUTPUT, 'model_loss.png')\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(len(train_losses)), train_losses, label='Train')\n",
    "    plt.plot(np.arange(len(valid_losses)), valid_losses, label='Validation')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.savefig(image_path)\n",
    "\n",
    "def plot_confusion_matrix(results, class_names, label_id, label_name):\n",
    "    PATH_OUTPUT = '../output/'\n",
    "    image_path = os.path.join(PATH_OUTPUT, 'Confusion_Matrix_'+label_name+'.png')\n",
    "\n",
    "    y_true, y_pred = zip(*results)\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = y_true[:,label_id]\n",
    "    y_pred = y_pred[:,label_id]\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    np.set_printoptions(precision=2)\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]), \n",
    "        yticks=np.arange(cm.shape[0]),\n",
    "        xticklabels=class_names, yticklabels=class_names,\n",
    "        title='Normalized Confusion Matrix\\n' + label_name,\n",
    "        ylabel='True',\n",
    "        xlabel='Predicted')\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "        rotation_mode=\"anchor\")\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt), \n",
    "                ha=\"center\", va=\"center\", \n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.savefig(image_path)\n",
    "\n",
    "def plot_roc(targets, probs, label_names):\n",
    "    PATH_OUTPUT = '../output/'\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    font = {'size' : 10}\n",
    "    plt.rc('font', **font)\n",
    "    fig = plt.figure(figsize=(21,6))\n",
    "    image_path = os.path.join(PATH_OUTPUT, 'ROC.png')\n",
    "    # ith observation to plot \n",
    "    for i, label_name in enumerate(label_names): \n",
    "        y_true = targets[:,i]\n",
    "        y_score = probs[:,i]\n",
    "\n",
    "        iwant = y_true < 2\n",
    "        y_true = y_true[iwant]\n",
    "        y_score = y_score[iwant]\n",
    "\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true, y_score)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        plt.subplot(2, 7, i+1)\n",
    "        plt.plot(fpr[i], tpr[i], color='b', lw=2, label='ROC (AUC = %0.2f)' % roc_auc[i])\n",
    "        plt.plot([0, 1], [0, 1], 'r--')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1.0])\n",
    "        if i >= 7:\n",
    "            plt.xlabel('False Positive Rate')\n",
    "        if i % 7 == 0:\n",
    "            plt.ylabel('True Positive Rate')\n",
    "        else:\n",
    "            plt.yticks([])\n",
    "        plt.title(label_name)\n",
    "        plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "    fig_size[0] = 30\n",
    "    fig_size[1] = 10\n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "    plt.savefig(image_path)\n",
    "\n",
    "def plot_pr(targets, probs, label_names):\n",
    "    PATH_OUTPUT = '../output/'\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    pr_auc = dict()\n",
    "    font = {'size' : 10}\n",
    "    plt.rc('font', **font)\n",
    "    fig = plt.figure(figsize=(21,6))\n",
    "    image_path = os.path.join(PATH_OUTPUT, 'PR.png')\n",
    "    for i, label_name in enumerate(label_names): \n",
    "        y_true = targets[:,i]\n",
    "        y_score = probs[:,i]\n",
    "\n",
    "        iwant = y_true < 2\n",
    "        y_true = y_true[iwant]\n",
    "        y_score = y_score[iwant]\t\n",
    "\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_true, y_score)\n",
    "        pr_auc[i] = auc(recall[i], precision[i])\n",
    "\n",
    "        plt.subplot(2, 7, i+1)\n",
    "        plt.plot(recall[i], precision[i], color='b', lw=2, label='PR (AUC = %0.2f)' % pr_auc[i])\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1.0])\n",
    "        if i >=7:\n",
    "            plt.xlabel('Recall')\n",
    "        if i % 7 == 0:\n",
    "            plt.ylabel('Precision')\n",
    "        else:\n",
    "            plt.yticks([])\n",
    "        plt.title(label_name)\n",
    "        plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "    fig_size[0] = 30\n",
    "    fig_size[1] = 10\n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "    plt.savefig(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheXpertDataSet(Dataset):\n",
    "    def __init__(self, data_dir, image_list_file, transform=None):\n",
    "        df = pd.read_csv(image_list_file)\n",
    "        df = df.fillna(0)\n",
    "        self.transform = transform\n",
    "        self.imagePaths = []\n",
    "        self.labels = []\n",
    "        for i, row in df.iterrows():\n",
    "            self.imagePaths.append( os.path.join(data_dir,row['Path']) )\n",
    "            # uncertainty labelling -- replace -1 with 2, \n",
    "            label = list(row[5:].values % 3) \n",
    "            self.labels.append(label)\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.imagePaths[index]).convert('RGB') \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.LongTensor(self.labels[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet121(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        # standard DenseNet121 architecture \n",
    "        super(DenseNet121, self).__init__()\n",
    "        self.densenet121 = torchvision.models.densenet121(pretrained=True, memory_efficient = True)\n",
    "        num_features = self.densenet121.classifier.in_features # 1024\n",
    "        self.densenet121.classifier = nn.Linear(num_features, num_labels*3)\n",
    "        self.num_labels = num_labels\n",
    "        # probability for each label - p0, p1, p2\n",
    "        self.num_classes = 3\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.densenet121(x)\n",
    "        return x.reshape([len(x), self.num_labels, self.num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "torch.manual_seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(0)\n",
    "\n",
    "PATH_DIR = '../DL_PROJ'\n",
    "PATH_TRAIN = './CheXpert-v1.0-small/train.csv'\n",
    "PATH_VALID = './CheXpert-v1.0-small/valid.csv'\n",
    "PATH_TEST = './CheXpert-v1.0-small/valid.csv'\n",
    "PATH_OUTPUT = \"../output/\"\n",
    "os.makedirs(PATH_OUTPUT, exist_ok=True)\n",
    "MODEL_OUTPUT = 'model.pth.tar'\n",
    "\n",
    "# set config parameters consistent with CheXpert paper\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 16 \n",
    "USE_CUDA = True  \n",
    "NUM_WORKERS = 8\n",
    "num_labels = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "\n",
    "transformseqTrain=transforms.Compose([\n",
    "                                    transforms.Resize(size=(320, 320)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    normalize\n",
    "                                ])\n",
    "\n",
    "transformseq=transforms.Compose([\n",
    "                                    transforms.Resize(size=(320, 320)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    normalize\n",
    "                                ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CheXpertDataSet(data_dir=PATH_DIR, image_list_file=PATH_TRAIN, transform = transformseqTrain)\n",
    "valid_dataset = CheXpertDataSet(data_dir=PATH_DIR, image_list_file=PATH_VALID, transform = transformseq)\n",
    "test_dataset = CheXpertDataSet(data_dir=PATH_DIR, image_list_file=PATH_TEST, transform = transformseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet121(num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Use\", torch.cuda.device_count(), \"GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and USE_CUDA else \"cpu\")\n",
    "model.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "PATH_MODEL = os.path.join(PATH_OUTPUT, \"model.pth\")\n",
    "if os.path.isfile(PATH_MODEL):\n",
    "    model = torch.load(PATH_MODEL)\n",
    "    print('Saved model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "\n",
    "best_val_loss = 1000000\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    scheduler.step() \n",
    "    print('Learning rate in epoch:', epoch)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(param_group['lr'])\n",
    "    train_loss = train(model, device, train_loader, criterion, optimizer, epoch)\n",
    "    valid_loss, valid_results = evaluate(model, device, valid_loader, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    is_best = valid_loss < best_val_loss  \n",
    "    if is_best:\n",
    "        best_val_loss = valid_loss\n",
    "        torch.save(model, os.path.join(PATH_OUTPUT, \"model.pth\"))\n",
    "\n",
    "print('Training finished, model saved')\n",
    "df_learning = pd.DataFrame(data = {'Train Loss':train_losses,'Valid Loss':valid_losses} )\n",
    "df_learning.index.name = 'Epoch'\n",
    "df_learning.to_csv(os.path.join(PATH_OUTPUT,'LearningCurves.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Negative', 'Positive', 'Uncertain']\n",
    "label_names = [ 'No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Lung Lesion', 'Edema', 'Consolidation',\n",
    "                'Pneumonia', 'Atelectasis', 'Pneumothorax', 'Pleural Effusion', 'Pleural Other', 'Fracture', 'Support Devices']\n",
    "\n",
    "for i, label_name in enumerate(label_names): \n",
    "    plot_confusion_matrix(test_results, class_names, i, label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_positive(model, device, data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    probas = np.array([])\n",
    "    targets = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(data_loader):\n",
    "            if isinstance(input, tuple):\n",
    "                input = tuple([e.to(device) if type(e) == torch.Tensor else e for e in input])\n",
    "            else:\n",
    "                input = input.to(device)\n",
    "            target = target.detach().to('cpu').numpy()\n",
    "            targets = np.concatenate((targets, target), axis=0) if len(targets) > 0 else target\n",
    "           \n",
    "            output = model(input) \n",
    "            y_pred = output.detach().to('cpu').numpy()\n",
    "            y_pred = y_pred[:,:,:2] \n",
    "            y_pred = softmax(y_pred, axis = -1)\n",
    "            # keep positive predictions \n",
    "            y_pred = y_pred[:,:,1] \n",
    "\n",
    "            probas = np.concatenate((probas, y_pred), axis=0) if len(probas) > 0 else y_pred\n",
    "    \n",
    "    return targets, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets, test_probs = predict_positive(best_model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(PATH_TEST)\n",
    "ids = df_test['Path'].copy().values\n",
    "for i, id in enumerate(ids):\n",
    "    ids[i] = id[33:45] \n",
    "test_targets_studies, test_probs_studies = [], []\n",
    "i = 0\n",
    "while i < len(ids):\n",
    "    j = i+1\n",
    "    target = test_targets[i]\n",
    "    while (j < len(ids)) and (ids[i] == ids[j]):\n",
    "        j += 1\n",
    "    y_pred = np.max(test_probs[i:j], axis = 0)\n",
    "    test_targets_studies.append(target)\n",
    "    test_probs_studies.append(y_pred)\n",
    "    i = j\n",
    "\n",
    "test_targets_studies = np.array(test_targets_studies)\n",
    "test_probs_studies = np.array(test_probs_studies)\n",
    "\n",
    "print(len(test_targets_studies))\n",
    "print(len(test_probs_studies))\n",
    "plot_roc(test_targets_studies, test_probs_studies, label_names)\n",
    "plot_pr(test_targets_studies, test_probs_studies, label_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
