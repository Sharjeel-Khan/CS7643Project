{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"u-ignore.ipynb","provenance":[],"authorship_tag":"ABX9TyPxEUFnf0DiqGiYaD3ctwKg"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"L4t4qeFiEvcR"},"source":["import os\n","import numpy as np\n","import time\n","import sys\n","import csv\n","import cv2\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.nn.functional as tfunc\n","from torch.utils.data import Dataset\n","from torch.utils.data.dataset import random_split\n","from torch.utils.data import DataLoader\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from PIL import Image\n","import torch.nn.functional as func\n","\n","from sklearn.metrics.ranking import roc_auc_score\n","import sklearn.metrics as metrics\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RsU6uFUYE4_P"},"source":["image_set_csv = 'CheXpert-v1.0-small/train.csv'\n","image_set = 'CheXpert-v1.0-small/train'\n","\n","valid_set_csv = 'CheXpert-v1.0-small/valid.csv'\n","valid_set = 'CheXpert-v1.0-small/valid'\n","\n","use_gpu = torch.cuda.is_available()\n","\n","pretrained = True                \n","classes = 14       \n","batch_size = 16\n","epochs = 3 \n","resize_im = 224\n","\n","class_names = ['No Finding', 'Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', \n","               'Lung Lesion', 'Edema', 'Consolidation', 'Pneumonia', 'Atelectasis', 'Pneumothorax', \n","               'Pleural Effusion', 'Pleural Other', 'Fracture', 'Support Devices']        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p_GNyrhdE6Rb"},"source":["class CheXpertDataSet(Dataset):\n","    def __init__(self, image_set_csv, image_set,set_type,transform=None):\n","        \"\"\"\n","        image_list_file: path to the file containing images with corresponding labels.\n","        transform: optional transform to be applied on a sample.\n","        \"\"\"\n","\n","        df_train = pd.read_csv(image_set_csv)\n","        # only keep if data still missing \n","        if set_type == 'train':\n","          listim = os.listdir(image_set) #change back\n","          newim = [x for x in df_train[\"Path\"] if x[x.rfind('train')+6:x.rfind('study')-1] in listim]\n","          df_train = df_train[df_train['Path'].isin(newim)]\n","        if set_type == 'valid':\n","          listim = os.listdir(image_set) #change back\n","          newim = [x for x in df_train[\"Path\"] if x[x.rfind('valid')+6:x.rfind('study')-1] in listim]\n","          df_train = df_train[df_train['Path'].isin(newim)]\n","        #till here\n","        df_train = df_train.fillna(0)\n","        self.image_names = list(df_train[\"Path\"])\n","        #self.image_names = ['/content/drive/My Drive/' + s for s in list(df_train[\"Path\"])] \n","        self.labels = np.asarray(df_train.iloc[:,5:])\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        \"\"\"Take the index of item and returns the image and its labels\"\"\"\n","        \n","        image_name = self.image_names[index]\n","        image = Image.open(image_name).convert('RGB')\n","        label = self.labels[index]\n","        if self.transform is not None:\n","            image = self.transform(image)\n","        return image, torch.FloatTensor(label)\n","\n","    def __len__(self):\n","        return len(self.image_names)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lJ4P5r7GE8lQ"},"source":["normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","transformList = []\n","transformList.append(transforms.RandomVerticalFlip())\n","transformList.append(transforms.Resize((resize_im, resize_im)))\n","transformList.append(transforms.ToTensor())\n","transformList.append(normalize)      \n","transformSequence=transforms.Compose(transformList)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OJFvqVViE_va"},"source":["dataset = CheXpertDataSet(image_set_csv,image_set,'train',transformSequence)\n","\n","# datasetVal, datasetTrain = random_split(dataset, [200, len(dataset) - 200]) #need to check \n","# datasetTest, datasetTrain = random_split(datasetTrain, [500, len(datasetTrain) - 500])\n","\n","datasetVal, datasetTrain = random_split(dataset, [200, len(dataset) - 200]) #need to check \n","#datasetVal, datasetTrain = random_split(dataset, [20, len(dataset) - 20])\n","datasetTest = CheXpertDataSet(valid_set_csv,valid_set,'valid',transformSequence)\n","# datasetTest, datasetTrain = random_split(datasetTrain, [500, len(datasetTrain) - 500])\n","\n","dataLoaderTrain = DataLoader(dataset=datasetTrain, batch_size=batch_size, shuffle=True,  num_workers=24, pin_memory=True)\n","dataLoaderVal = DataLoader(dataset=datasetVal, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n","dataLoaderTest = DataLoader(dataset=datasetTest, batch_size=batch_size, shuffle=False, num_workers=24, pin_memory=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nC9EcqyyFDT_"},"source":["#ignoring uncertain label to compute loss\n","def u_ignore_bce(output, target):\n","    m = -1 \n","    eps = 1e-8\n","    loss = (target*torch.log(output.clamp(eps, 1-eps)) +\n","                    (1-target)*torch.log((1 - output).clamp(eps, 1-eps)))\n","    loss = -((target != m).float()*loss).sum(1).mean()\n","    return loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rm9ll8DzFF4D"},"source":["#transfer learning model \n","class DenseNet121(nn.Module):\n","\n","    def __init__(self, classNum, pretrained):\n","\t\n","        super(DenseNet121, self).__init__()\n","\t\t\n","        self.densenet121 = torchvision.models.densenet121(pretrained=pretrained,memory_efficient=True)\n","        prevNum = self.densenet121.classifier.in_features\n","        #replacing classifier FC for 14 classes\n","        self.densenet121.classifier = nn.Sequential(nn.Linear(prevNum, classNum), nn.Sigmoid())\n","\n","    def forward(self, x):\n","        x = self.densenet121(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ROP12XOFHaA"},"source":["class ChexpertTrainer():\n"," \n","    def train (dataloaderTrain, dataloaderVal, pretrained, classes, batch_size, epoch, resize_im, launchTimestamp, checkpoint):\n","\n","        \n","        #-------------------- SETTINGS: NETWORK ARCHITECTURE\n","        model = DenseNet121(classes, pretrained).cuda()\n","        # model = torch.nn.DataParallel(model).cuda()\n","\n","        #-------------------- SETTINGS: OPTIMIZER & SCHEDULER\n","        optimizer = optim.Adam (model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n","        scheduler = ReduceLROnPlateau(optimizer, factor = 0.1, patience = 5, mode = 'min')\n","        \n","        #---- Load checkpoint \n","        if checkpoint != None and use_gpu:\n","            modelCheckpoint = torch.load(checkpoint)\n","            model.load_state_dict(modelCheckpoint['state_dict'])\n","            optimizer.load_state_dict(modelCheckpoint['optimizer'])\n","\n","        \n","        #---- TRAIN THE NETWORK\n","        \n","        lossMIN = 100000\n","        \n","        for epochID in range (0, epoch):\n","            \n","            timestampTime = time.strftime(\"%H%M%S\")\n","            timestampDate = time.strftime(\"%d%m%Y\")\n","            timestampSTART = timestampDate + '-' + timestampTime\n","                         \n","            ChexpertTrainer.epochTrain (model, dataLoaderTrain, optimizer, scheduler, epoch, classes, u_ignore_bce)\n","            lossVal, losstensor = ChexpertTrainer.epochVal (model, dataLoaderVal, optimizer, scheduler, epoch, classes, u_ignore_bce)\n","            \n","            timestampTime = time.strftime(\"%H%M%S\")\n","            timestampDate = time.strftime(\"%d%m%Y\")\n","            timestampEND = timestampDate + '-' + timestampTime\n","            \n","            scheduler.step(losstensor)\n","            \n","            if lossVal < lossMIN:\n","                lossMIN = lossVal    \n","                torch.save({'epoch': epochID + 1, 'state_dict': model.state_dict(), 'best_loss': lossMIN, 'optimizer' : optimizer.state_dict()}, 'models/'+'m-' + launchTimestamp + '.pth.tar')\n","                print ('Epoch [' + str(epochID + 1) + '] [save] [' + timestampEND + '] loss= ' + str(lossVal))\n","            else:\n","                print ('Epoch [' + str(epochID + 1) + '] [----] [' + timestampEND + '] loss= ' + str(lossVal))\n","                     \n","    #-------------------------------------------------------------------------------- \n","       \n","    def epochTrain (model, dataLoader, optimizer, scheduler, epochMax, classCount, loss):\n","        \n","        model.train()\n","        \n","        \n","        for batchID, (input, target) in enumerate (dataLoader):\n","            \n","#             print(input.shape)\n","#             print(target.shape)\n","\n","            input = input.cuda()\n","            target = target.cuda(non_blocking = True)\n","       \n","            varOutput = model(input)\n","            lossvalue = loss(varOutput, target)\n","\n","            optimizer.zero_grad()\n","            lossvalue.backward()\n","            optimizer.step()\n","            \n","    #-------------------------------------------------------------------------------- \n","        \n","    def epochVal (model, dataLoader, optimizer, scheduler, epochMax, classCount, loss):\n","        \n","        model.eval()\n","        \n","        lossVal = 0\n","        lossValNorm = 0\n","        \n","        losstensorMean = 0\n","        \n","        with torch.no_grad():\n","        \n","            for i, (input, target) in enumerate (dataLoader):\n","\n","                input = input.cuda()\n","                target = target.cuda(non_blocking = True)\n"," \n","                varOutput = model(input)\n","\n","                losstensor = loss(varOutput, target)\n","                losstensorMean += float(losstensor)\n","\n","                lossVal += float(losstensor) #or losstensor.item()\n","                lossValNorm += 1\n","\n","            outLoss = lossVal / lossValNorm\n","            losstensorMean = losstensorMean / lossValNorm\n","        \n","        return outLoss, losstensorMean\n","    \n","    def computeAUROC (dataGT, dataPRED, classCount):\n","        \n","        outAUROC = []\n","        \n","        datanpGT = dataGT.cpu().numpy()\n","        datanpPRED = dataPRED.cpu().detach().numpy()\n","        print(datanpGT)\n","        print(datanpGT.shape)\n","        print(datanpPRED)\n","        print(datanpPRED.shape)\n","        print(datanpPRED[:,0].shape)\n","        for i in range(classCount):\n","            print(i)\n","            try:\n","                outAUROC.append(roc_auc_score(datanpGT[:, i], datanpPRED[:, i]))\n","            except ValueError:\n","                pass\n","\n","        return outAUROC\n","            \n","    def test (dataloaderTest, pathModel, classes, pretrained, batch_size, resize_im, launchTimeStamp, class_names):   \n","        \n","        cudnn.benchmark = True\n","        \n","        #-------------------- SETTINGS: NETWORK ARCHITECTURE, MODEL LOAD\n","        model = DenseNet121(classes, pretrained).cuda()\n","        \n","        modelCheckpoint = torch.load(pathModel)\n","        model.load_state_dict(modelCheckpoint['state_dict'])\n","        \n","        outGT = torch.FloatTensor().cuda()\n","        outPRED = torch.FloatTensor().cuda()\n","       \n","        model.eval()\n","        \n","\n","        for i, (input, target) in enumerate(dataLoaderTest):\n","\n","          input = input.cuda()\n","          target = target.cuda()\n","          outGT = torch.cat((outGT, target), 0).cuda()\n","\n","          bs, c, h, w = input.size()\n","          varInput = input.view(-1, c, h, w)\n","            \n","          out = model(varInput)\n","          outPRED = torch.cat((outPRED, out), 0)\n","\n","        aurocIndividual = ChexpertTrainer.computeAUROC(outGT, outPRED, classes)\n","        aurocMean = np.array(aurocIndividual).mean()\n","        \n","        print ('AUROC mean ', aurocMean)\n","        \n","        for i in range (0, len(aurocIndividual)):\n","            print (class_names[i], ' ', aurocIndividual[i])\n","        \n","        return outGT, outPRED\n","#-------------------------------------------------------------------------------- "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pSa6UYUzJ7hl"},"source":["timestampTime = time.strftime(\"%H%M%S\")\n","timestampDate = time.strftime(\"%d%m%Y\")\n","timestampLaunch = timestampDate + '-' + timestampTime\n","       \n","pathModel = 'm-' + timestampLaunch + '.pth.tar'\n","    \n","print ('Training NN architecture')\n","ChexpertTrainer.train(dataLoaderTrain, dataLoaderVal, pretrained, classes, batch_size, epochs, resize_im, timestampLaunch, None)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JoZb-mNlJ-hC"},"source":["print(os.listdir('models/'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jk2SwHESKA-P"},"source":["pathModel = 'models/m-19112020-005639.pth.tar'\n","print ('Testing the trained model')\n","outGT1, outPRED1 = ChexpertTrainer.test(dataLoaderTest, pathModel, classes, pretrained, batch_size, resize_im, timestampLaunch, class_names)"],"execution_count":null,"outputs":[]}]}